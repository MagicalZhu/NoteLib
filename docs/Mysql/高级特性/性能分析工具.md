---
id: 性能分析工具
title: 性能分析工具
---

在数据库调优中,我们的目标是`响应时间快、吞吐量大`,利用监测工具和日志分析可以帮我们快速的找到调优的思路和方式

## 数据库的优化步骤

当我们遇到数据库调优问题的时候，该如何思考呢?这里把思考的流程整理成下面这张图

整个流程划分成了`观察(Show status)`和`行动(Action)`两个部分。**字母S的部分代表观察(会使用相应的分析工具)，字母 A 代表的部分是行动(对应分析可以采取的行动)**

*![image-20220731105832978](./image/性能分析工具/image-20220731105832978.png)*



## 查看系统性能参数

### 概述

- 在 MySQL,我们可以使用`SHOW STATUS`语句查看一些 MySQL 数据库服务器的`性能参数、执行频率`
- **语法格式**
  - `SHOW [GLOBAL | SESSION] STATUS LIKE '参数'`
- <mark>我们可以使用<strong>慢查询次数</strong>参数,结合慢查询日志找出慢查询语句,然后针对慢查询语句进行<strong>表结构优化</strong>或者<strong>查询语句优化</strong></mark>

**常用的参数列表**

| 参数名                 | 说明                                                       |
| ---------------------- | ---------------------------------------------------------- |
| `Connections`          | 连接MySQL服务器的次数                                      |
| `Uptime`               | MySQL服务器的上线时间,单位**秒**                           |
| `Slow_queries`         | 慢查询的次数                                               |
| `Innodb_rows_read`     | Select查询返回的行数                                       |
| `Innodb_rows_inserted` | 执行INSERT操作插入的行数                                   |
| `Innodb_rows_updated`  | 执行UPDATE操作更新的行数                                   |
| `Innodb_rows_deleted`  | 执行DELETE操作删除的行数                                   |
| `Com_select`           | 查询操作的次数                                             |
| `Com_insert`           | 插入操作的次数。**对于批量插入的 INSERT 操作，只累加一次** |
| `Com_update`           | 更新操作的次数                                             |
| `Com_delete`           | 删除操作的次数                                             |

:::info 示例

**1.查看 MySQL 服务器连接次数**

```sql
mysql> show status like 'Connections';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| Connections   | 11    |
+---------------+-------+
```



**2. 查看MySQL 服务器上线时间**

```sql
-- 时间的单位是 s
mysql> show status like 'Uptime';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| Uptime        | 11945 |
+---------------+-------+
```



**3.查看CRUD 的行数**

```sql
mysql> show status like 'innodb_rows_%';
+----------------------+-------+
| Variable_name        | Value |
+----------------------+-------+
| Innodb_rows_deleted  | 0     |
| Innodb_rows_inserted | 0     |
| Innodb_rows_read     | 0     |
| Innodb_rows_updated  | 0     |
+----------------------+-------+

mysql> select * from course;        
+-----+-----------+-------------+
| id  | course_id | course_name |
+-----+-----------+-------------+
|   1 |     10073 | jNmVQs      |
|   2 |     10035 | JuUoLL      |
|  98 |     10035 | YQkAXl      |
/*..............................*/
|  99 |     10022 | zOuFVM      |
| 100 |     10094 | yDxAkA      |
+-----+-----------+-------------+
100 rows in set (0.00 sec)

mysql> show status like 'innodb_rows_%';
+----------------------+-------+
| Variable_name        | Value |
+----------------------+-------+
| Innodb_rows_deleted  | 0     |
| Innodb_rows_inserted | 0     |
| Innodb_rows_read     | 100   |
| Innodb_rows_updated  | 0     |
+----------------------+-------+
4 rows in set (0.00 sec)
```

:::

### SQL查询成本(last_query_cost)

>  一条SQL 查询语句在执行前需要确定一个**执行计划**,如果存在多种执行计划, 那么MySQL 会计算每个执行计划所需要的成本, 最后从中选择**成本最小**的一个作为最终执行的执行计划

- 如果想查看某条 SQL 语句的执行成本,**可以在执行完这个 SQL 语句之后,通过查看`当前会话`中的性能参数 `last_query_cost`的变量值来得到执行成本 **。SQL 查询成本通常也是我们**评价一个查询的执行效率的常用指标**, 这个查询成本对应的是`SQL 语句所需要读取的页的数量`

- **在对于比较开销是非常有用的，特别是我们有好几种查询方式可选的时候,我们可以采用这种方式**

:::info 示例

**查询student_info 中指定 student_id 的学生信息,观察是否有索引的区别**

```sql
-- 没有为 student_id加上索引,耗时 0.24s
mysql> select * from  student_info where student_id=1234;    
+--------+------------+--------+-----------+----------+---------------------+
| id     | student_id | name   | course_id | class_id | create_time         |
+--------+------------+--------+-----------+----------+---------------------+
| 505843 |       1234 | OTdMwX |     10025 |    10150 | 2022-07-17 16:35:45 |
+--------+------------+--------+-----------+----------+---------------------+
1 row in set (0.24 sec)

-- 这里加载了 100489 个数据页
mysql> show status like 'last_query_cost';
+-----------------+---------------+
| Variable_name   | Value         |
+-----------------+---------------+
| Last_query_cost | 100488.649000 |
+-----------------+---------------+
1 row in set (0.00 sec)

-- 为 student_id加上索引
mysql> create index idx_sid on student_info (student_id);
Query OK, 0 rows affected (2.71 sec)
Records: 0  Duplicates: 0  Warnings: 0

mysql> select * from  student_info where student_id=1234;
+--------+------------+--------+-----------+----------+---------------------+
| id     | student_id | name   | course_id | class_id | create_time         |
+--------+------------+--------+-----------+----------+---------------------+
| 505843 |       1234 | OTdMwX |     10025 |    10150 | 2022-07-17 16:35:45 |
+--------+------------+--------+-----------+----------+---------------------+
1 row in set (0.00 sec)

-- 这里加载了 1 个数据页
mysql> show status like 'last_query_cost';
+-----------------+----------+
| Variable_name   | Value    |
+-----------------+----------+
| Last_query_cost | 0.349000 |
+-----------------+----------+
1 row in set (0.00 sec)
```

<mark>我们可以看到加上索引后,SQL 查询成本很低,相差了数十万个数量级。但是在查询时间上并没有这个数量级的体现</mark>

实际上这两个 **SQL 查询的时间基本上相差相对不大**， 就是因为采用了`顺序读取`的方式将页面一次性加载到缓冲池中，然后再进行查找。虽然 `last_query_cost增加了不少 `，但是通过`缓冲池`的机制，并 **没有增加多少查询时间** 

:::

### 小结说明

SQL 查询是一个动态的过程,从页加载的角度上说,可以有两点结论:

1. `位置决定效率`
   - 如果页就在数据库`缓冲池`,那么效率是最好的,否则还需要从`内存`或者`磁盘`中进行读取
   - 当然了,对于单个页来说,从内存中读取肯定比从磁盘读取效率高得多
2. `批量决定效率`
   - 如果我们从磁盘中对单一页进行随机读取,那么效率是很低的,差不多 10ms。而采用顺序读取的方式,批量对页进行读取,平均每页的读取效率会提升很多,甚至要快于单个页面在内存中的随机读取

所以说,遇到 IO 不用担心,如果方法对的话,效率也是很高的。

**我们首先需要考虑数据存放的位置,如果是经常使用的数据就要尽量放在**`缓冲池`**中,然后可以充分利用磁盘的吞吐能力,一次性批量读取数据,这样单个页的读取效率就得到了提升**

## 定位慢SQL(慢查询日志)

- MySQL 的慢查询日志,用于记录 MySQL 中`响应时间超过阈值`的语句,具体指运行时间超过`long_query_time`值的 SQL,就会被记录到慢查询日志中。
  - **long_query_time** 的默认值是`10`,意思是执行 10s以上的语句,就是一个慢 SQL

- 慢查询日志主要作用是,帮助发现那些执行时间特别长的 SQL 查询,并且针对这些 SQL 语句进行优化。当我们的数据库发生阻塞、运行变慢的时候,可以检查一些慢查询日志,找出那些慢查询
- **默认情况下,MySQL 数据库`没有开启慢查询日志`,需要手动的设置这个参数**,`如果不是调优需要的话,一般不建议启动这个参数`,因为开启慢查询日志本身会有一些性能的影响
- <mark>慢查询支持将日志记录写入到文件中</mark>

:::tip 补充

实际上,**控制慢查询日志的还有一个系统变量:**`min_examined_row_limit`, 这个变量的意思是,查询`扫描过的最少记录数`

这个变量和查询时间(long_query_time),共同组成了判断一个查询是否是慢查询的条件,即**查询扫描的记录数大于等于min_examined_row_limit,且查询执行时间超过 long_query_time 的 SQL 查询就是慢查询**

<mark>min_examined_row_limit 的默认值是 0</mark> 

```sql
mysql> show variables like '%min_examined_row_limit%';   
+------------------------+-------+
| Variable_name          | Value |
+------------------------+-------+
| min_examined_row_limit | 0     |
+------------------------+-------+
1 row in set (0.00 sec)
```

:::

### 查看慢查询日志参数

1. **查看slow_query_log 参数**

   ```sql
   -- 查看 slow_query_log 参数
   show variables like '%slow_query_log%'
   ```

2. **查看 long_query_time 参数**

   ```sql
   -- 查看 long_query_time 参数值
   show variables like '%long_query_time%'
   ```

:::info 演示示例

```sql
mysql> show variables like '%long_query_time%';
+-----------------+-----------+
| Variable_name   | Value     |
+-----------------+-----------+
| long_query_time | 10.000000 |
+-----------------+-----------+
1 row in set (0.00 sec)

mysql> show variables like '%long_query_log%';
Empty set (0.00 sec)

mysql> show variables like '%slow_query_log%';    
+---------------------+-----------------------------------+
| Variable_name       | Value                             |
+---------------------+-----------------------------------+
| slow_query_log      | OFF                               |
| slow_query_log_file | /var/lib/mysql/localhost-slow.log |
+---------------------+-----------------------------------+
2 rows in set (0.00 sec)
```



:::

### 开启慢查询日志(临时)

分为以下两个步骤:

1. `开启 slow_query_log 参数`

   ```sql
   SET GLOBAL slow_query_log='ON';
   ```

2. `修改 long_query_time 阈值`

   ```sql
   -- 设置 long_query_time 值,这里设置为 1s
   SET long_query_time=1;
   ```

### 查看慢查询数量

我们可以查询当前系统中有多少条满查询记录

```sql
SHOW STATUS LIKE '%slow_queries%';
```

:::info 演示示例

**1.准备数据**

```sql
-- 准备的表
CREATE TABLE `student` (
  `id` INT(11) NOT NULL AUTO_INCREMENT, `stuno` INT NOT NULL ,
  `name` VARCHAR(20) DEFAULT NULL,
  `age` INT(3) DEFAULT NULL,
  `classId` INT(11) DEFAULT NULL, PRIMARY KEY (`id`)
) ENGINE=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;


-- 准备的存储过程,其他两个存储过程再前一章节
CREATE PROCEDURE insert_stu1( START INT , max_num INT ) 
BEGIN
	DECLARE i INT DEFAULT 0;
	SET autocommit = 0; #设置手动提交事务
	REPEAT #循环
	SET i=i+1; #赋值
	INSERT INTO student (stuno, NAME ,age ,classId ) VALUES
	((START+i),rand_string(6),rand_num(10,100),rand_num(10,1000)); 
	UNTIL i = max_num
	END REPEAT;
	COMMIT; #提交事务
END

-- 调用存储过程
CALL insert_stu1(100001,4000000)
```



**2.执行一段耗时长的 SQL,并查看是否被慢查询记录**

```sql
-- 执行 SQL 语句之前看到没有慢查询记录
mysql> show status like '%slow_queries%';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| Slow_queries  | 0     |
+---------------+-------+
1 row in set (0.00 sec)


-- 执行一段耗时长的 SQL 语句
mysql> SELECT * FROM student WHERE stuno = 3455655;
+---------+---------+--------+------+---------+
| id      | stuno   | name   | age  | classId |
+---------+---------+--------+------+---------+
| 5503915 | 3455655 | bHfJQl |   69 |     584 |
+---------+---------+--------+------+---------+
1 row in set (1.00 sec)

-- 这里可以看到记录了一条慢查询
mysql> show status like '%slow_queries%';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| Slow_queries  | 1     |
+---------------+-------+
1 row in set (0.00 sec)

```

:::



### 慢日志分析工具(mysqldumpslow)

> 在生产环境中，如果要手工分析日志，查找、分析SQL，显然是个体力活，MySQL提供了日志分析工具`mysqldumpslow`

- `mysqldumpslow [ OPTS... ] [ LOGS... ]`
  - OPT 可选参数
    - `-a`
      - **不将数字抽象成N，字符串抽象成S**
    - `-s`
      - **表示按照何种方式排序**,有以下可选值
        - **c**: 访问次数 
        - **l**: 锁定时间 
        - **r**: 返回记录 
        - **t**: 查询时间 
        - **al**:平均锁定时间  
        - **ar**:平均返回记录数  
        - **at**:平均查询时间 (默认方式)  
        - **ac**:平均查询次数
    - `-t`
      - **返回前面多少条的数据**
    - `-g`
      - **后边搭配一个正则匹配模式，大小写不敏感的**
  - <mark>这里日志路径可以通过 参数 slow_query_log_file 看到</mark> 

- **工作常用参考**

  ```sql
  #得到返回记录集最多的10个SQL
  mysqldumpslow -s r -t 10 logPath
  
  #得到访问次数最多的10个SQL
  mysqldumpslow -s c -t 10 logPath
  
  #得到按照时间排序的前10条里面含有左连接的查询语句
  mysqldumpslow -s t -t 10 -g "left join"logPath
  
  #另外建议在使用这些命令时结合 | 和more 使用 ，否则有可能出现爆屏情况 
  mysqldumpslow -s r -t 10 logPath | more
  ```

   

:::info 示例

![image-20220731144045768](./image/性能分析工具/image-20220731144045768.png)

:::



### 关闭慢查询日志

关闭 MySQL 服务器的慢查询日志功能有两种方法:

1. **修改 MySQL配置文件(永久的)**

   ```ini
   [mysqld]
   # slow_query_log=OFF
   ```

2. **语句修改(临时的)**

   ```sql
   SET GLOBAL slow_query_log=off;
   ```

###  重置慢查询日志

- 语法格式
  - `mysqladmin -uroot -p flush-logs slow`

## 查看 SQL 执行成本

### 开启 profiling

- 确认`profiling` 是否开启, **profiling = 0 | OFF**  表示关闭

  ```sql
  select @@profiling;
  show variables like 'profiling';
  ```

- 开启 `profiling` 

  ```sql
  # 开启 Session 级别的 profiling
  set  profiling = 1
  ```


### 查看 profiles

- <mark>查看当前会话产生的所有 profiles</mark>

- 基本语法

  ```sql
  show profiles;
  ```

  ![image-20220731150806898](./image/性能分析工具/image-20220731150806898.png)

###  **查看**profile

- 基本语法

  ```sql
  show profile [type [, type] ... ]
  [FOR QUERY query_id]      
  [LIMIT row_count [OFFSET offset]]
  ```

- 命令参数说明

  - `type`
    - `ALL`  : 显示所有的开销信息
    - `BLOCK IO ` : 显示块IO相关开销
    - `CONTEXT SWITCHES` : 上下文切换相关开销
    - `CPU` : 显示CPU相关开销信息
    - `IPC` : 显示发送和接收相关开销信息
    - `MEMORY` ： 显示内存相关开销信息
    - `PAGE FAULTS ` : 显示页面错误相关开销信息
    - `SOURCE` : 显示和Source_function，Source_file，Source_line相关的开销信息
    - `SWAPS` : 显示交换次数相关开销的信息
  - `query_id`
    - 如果不指定，只是显示最近执行的语句，如果指定会显示语句的 profile
    - 可以通过 `show profiles;` 得到 query_id

  :::info 使用 show profile

  ![image-20220731150728543](./image/性能分析工具/image-20220731150728543.png)

  :::

### 小结说明

日常开发需要注意:

1. `converting HEAP ti MyISAM`
   - 结果内存太大,内存不够,数据向磁盘上搬
2. `creating tmp table`
   - 创建临时表,先拷贝数据到临时表,用完再删除临时表
3. `copying to tmp table on disk`
   - 把内存中临时表复制到磁盘上✋
4. `locked`

**如果在 show_profile诊断结果中出现了上述 4 条中的任意一条,则 sql 需要优化**

:::caution 注意

SHOW PROFILE 命令将被弃用,可以从 `information_schema` 中的 profiling 数据表中进行查看

:::

## 分析查询语句(Explain)

### 概述

> 定位了慢 SQL 之后,我们可以使用`Explain` 或`Describe` 工具做针对性的分析,**Describe**的使用方法和 Explain 是一样的,且分析结果也是一样的
>
> MySQL 中有专门负责优化 Select 语句的优化器模块,为客户端请求的 Sql 查询提供它认为的最优的`执行计划`
>
> 这个执行计划展示了接下来具体执行查询的方式,比如多表连接的顺序是什么、对于每个表采用什么访问方法来具体执行查询等。MySQL 为我们提供了`Explain`语句帮助我们查看某个查询语句的具体执行计划是什么

- 可以做什么
  1. 表的读取顺序
  2. 数据读取操作的操作类型
  3. 哪些索引可以被使用
  4. **哪些索引被实际使用**
  5. 表之间的引用
  6. **每张表有多少行被优化器查询**
- 官网介绍
  - [MySQL5.7](https://dev.mysql.com/doc/refman/5.7/en/explain-output.html)
  - [MySQL8.0](https://dev.mysql.com/doc/refman/8.0/en/explain-output.html)
- **版本说明**
  - MySQL 5.6.3 之前只能 **Explain Select 语句**,之后就可以使用**Explain Delete/Update/Insert**
- Explain 总结相关的博客
  - [最完整的Explain总结，SQL优化不再困难](https://blog.51cto.com/u_14299052/2986347)


### 基本语法

- `Explain SELECT | DELETE | INSERT | UPDATE语句`
- **Explain 输出说明**
  - `id`
    - 在一个大的查询语句中每个SELECT关键字都对应一个 **唯一的id**
  - `select_type`
    - Select 关键字对应的那个查询的类型
  - `table`
    - 表名
  - `partitions`
    - 匹配的分区信息
  - `type`
    - 针对单表的访问方法
  - `possible_keys`
    - 可能用到的索引
  - `key`
    - 实际用到的索引
  - `key_len`
    - 实际使用到的索引长度
  - `ref`
    - 当使用索引列等值查询时，与索引列进行等值匹配的对象信息
  - `rows`
    - 预估的需要读取的记录条数
  - `filtered`
    - 某个表经过搜索条件过滤后剩余记录条数的百分比
  - `Extra`
    - 一些额外的信息

### 准备数据

```sql
-- 建立表
CREATE TABLE s1 (
	id INT AUTO_INCREMENT,
	key1 VARCHAR(100),
	key2 INT,
	key3 VARCHAR(100),
	key_part1 VARCHAR(100),
	key_part2 VARCHAR(100),
	key_part3 VARCHAR(100),
	common_field VARCHAR(100),
	PRIMARY KEY (id),
	INDEX idx_key1 (key1),
	UNIQUE INDEX idx_key2 (key2),
	INDEX idx_key3 (key3),
	INDEX idx_key_part(key_part1, key_part2, key_part3)
) ENGINE=INNODB CHARSET=utf8;


CREATE TABLE s2 (
	id INT AUTO_INCREMENT,
	key1 VARCHAR(100),
	key2 INT,
	key3 VARCHAR(100),
	key_part1 VARCHAR(100), 
	key_part2 VARCHAR(100),
	key_part3 VARCHAR(100), 
	common_field VARCHAR(100), 
	PRIMARY KEY (id),
	INDEX idx_key1 (key1),
	UNIQUE INDEX idx_key2 (key2),
	INDEX idx_key3 (key3),
	INDEX idx_key_part(key_part1, key_part2, key_part3) 
) ENGINE=INNODB CHARSET=utf8;


-- 设置变量
set global log_bin_trust_function_creators=1;

-- 创建函数,该函数会返回一个字符串
CREATE FUNCTION rand_string1(n INT) RETURNS VARCHAR(255)  
BEGIN
	DECLARE chars_str VARCHAR(100) DEFAULT 'abcdefghijklmnopqrstuvwxyzABCDEFJHIJKLMNOPQRSTUVWXYZ';
	DECLARE return_str VARCHAR(255) DEFAULT ''; DECLARE i INT DEFAULT 0;
WHILE i < n DO
	SET return_str =CONCAT(return_str,SUBSTRING(chars_str,FLOOR(1+RAND()*52),1));
	SET i = i + 1; END WHILE;
	RETURN return_str; 
END 

-- 定义存储过程1,向 s1 插入数据
CREATE PROCEDURE insert_s1 (IN min_num INT (10),IN max_num INT (10)) 
BEGIN
  DECLARE i INT DEFAULT 0; SET autocommit = 0; 
  REPEAT
  	SET i = i + 1;
  		INSERT INTO s1 VALUES( (min_num + i), 
                            rand_string1(6),
                            (min_num + 30 * i + 5), 
                            rand_string1(6),
                            rand_string1(10), 
                            rand_string1(5),
                            rand_string1(10),
                            rand_string1(10)); 
      UNTIL i = max_num
  END REPEAT;
  COMMIT;
 END 

-- 定义存储过程2,向 s2 插入数据
CREATE PROCEDURE insert_s2 (IN min_num INT (10),IN max_num INT (10)) 
  BEGIN
    DECLARE i INT DEFAULT 0; SET autocommit = 0;
    REPEAT
      SET i = i + 1;
      INSERT INTO s2 VALUES( (min_num + i),
      rand_string1(6), 
      (min_num + 30 * i + 5), 
      rand_string1(6), 
      rand_string1(10), 
      rand_string1(5),
      rand_string1(10), 
      rand_string1(10));
      UNTIL i = max_num 
      END REPEAT; 
    COMMIT;
	END 
	
-- 执行存储过程 1
CALL insert_s1(10001,10000);

-- 执行存储过程 2
CALL insert_s2(10001,10000);
```



### 输出结果列作用

#### table

- **说明** 
  - `查询的每一行记录都对应一个单表(包括临时表)`

  - 不论我们的查询语句有多复杂，包含了多少个表 ，**到最后也是需要对每个表进行`单表访问`的**
    - 即 MySQL 规定 `EXPLAIN语句输出的每条记录都对应着某个单表的访问方法`

  - 该条记录的table列代表着该表的表名(有时不是真实的表名字，可能是简称)

- **小结**
  - <mark>多表关联查询中,会有多行记录,前面的表称为:驱动表,后面的的表称为:被驱动表</mark>
  - <mark>如果使用了 union 进行去重,还会有张临时表</mark> 


:::info 示例

**1、只查询一个单表**

![image-20220731155757634](./image/性能分析工具/image-20220731155757634.png)

**2、多表关联查询**

**这里的 s1 就是驱动表,s2 就是被驱动表**

![image-20220731155848406](./image/性能分析工具/image-20220731155848406.png)

:::

#### id

- **说明**
  - 在一个大的查询语句中**每个 SELECT都对应一个唯一的 id**,即复杂的子查询会有多个 id
  - **查询优化器可能会对涉及子查询的查询语句进行重写,转变为一个多表查询的操作**
- **小结**
  - <mark><strong>id列越大执行优先级越高，id相同则从上往下执行，id为NULL最后执行</strong></mark>
  - <mark><strong>关注点:id号每个号码，表示一趟独立的查询, 一个sql的查询次数越少越好</strong></mark>

:::info

**1.单表查询,只有一个 Select 关键字**

很明显只有一条记录,也只有一个 id

![image-20220731163649451](./image/性能分析工具/image-20220731163649451.png)

<br/>

**2. 多表关联,但是也只有一个 Select 关键字**

我们看到,虽然多表关联查询了,但由于只有一个 Select 语句,所以 id 都是一样的 **1**

![image-20220731163842827](./image/性能分析工具/image-20220731163842827.png)

<br/>

**3.子查询,包含了两个 Select 关键字**

从输出结果可以看到:

- s1表在外层查询中,外层查询有一个独立的SELECT关键字，所以第一条记录的id值就是1。

- t2表在子查询中，子查询有一个独立的SELECT关键字，所以第二条记录的id值就是2。

![image-20220731164509738](./image/性能分析工具/image-20220731164509738.png)

<br/>

**4.查询优化器是会对子查询语句重写的**

虽然我们的查询语句是一个子查询，但是执行计划中s1和s2表对应的记录的id值全部是1，这就表明了查询优化器将子查询转换为了多表的连接查询

![image-20220731164758523](./image/性能分析工具/image-20220731164758523.png)



**5.Union 和 Union All**

union 去重需要使用临时表,所以有 3条记录,最后一条的 table 是<union1,2>, 但是 Union All 不需要,所以只有两条记录。它们都有两个 Select 关键字,所以id 有[1,2]

![image-20220731165556395](./image/性能分析工具/image-20220731165556395.png)

:::

#### select_type

> 一个查询语句中可以包含若干个 SELECT 关键字,**每个SELECT关键字代表着一个小的查询语句**,而每个 SELECT 关键字的 FROM 子句中都可以包含若干张表(用于连接查询)。**每张表都对应着执行计划(explain)输出中的一条记录**, 对于在同一个 SELECT 关键字中的表来说,它们的 id 值是相同的

MySQL 为每个 SELECT 关键字代表的“小查询” 都定义了一个`select_type`的属性。通过这个属性值,我们可以知道`小查询在大查询中起了什么作用`

**select_type 有以下的取值:**

- `SIMPLE`
- `PRIMARY`
- `UNION`
- `UNION RESULT`
- `DEPENDENT UNION`
- `SUBQUERY`
- `DEPENDENT SUBQUERY`
- `DERIVED`
- `MATERIALIZED`
- `UNCACHEABLE SUBQUERY	`
- `UNCACHEABLE UNION`

<mark>需要注意的是:优化器会对我们的查询语句进行它认为的优化,所以有时候 select_type 与实际编写的 sql 语句并不匹配</mark>,特别是子查询,会将子查询转为多表 join 的方式 

##### SIMPLE

- 没有使用 union 、union all 、子查询, 当然<mark>多表连接查询也算是 simple 类型</mark> 

![image-20220731223535309](./image/性能分析工具/image-20220731223535309.png)



##### PRIMARY、UNION、UNION RESULT

1. 对于包含 `UNION、UNION ALL、子查询`的大查询来说,它是由几个小查询组成的,其中最左边的查询的 query_type 值就是`PRIMARY`

2. 对于包含 `UNION、UNION ALL`的大查询来说,它是由几个小查询组成的,除了最左边的小查询,其他小查询的 query_type 值就是`UNION`

3. MySQL 使用临时表来完成`UNION`的去重工作,针对该临时表的查询的query_type 值就是`UNION RESULT`

:::info 示例

我们可以看到,UNION 与 UNION ALL 最左侧的查询(s1) 都是 **PRIMARY**的,其他的是**UNION**。然后UNION 由于需要去重,还增加了一个临时表的查询(**UNION RESULT**)

![image-20220731225140837](./image/性能分析工具/image-20220731225140837.png)

:::

##### SUBQUERY

**如果包含**`子查询`**的查询语句不能转为对应的多表 join 连接查询,并且该子查询是**`不相关子查询`,**那么该子查询的第一个 SELECT 关键字对应的查询就是**`SUBQUERY`

![image-20220731230246005](./image/性能分析工具/image-20220731230246005.png)



##### DEPENDENT SUBQUERY

**如果包含**`子查询`**的查询语句不能转为对应的多表 join 连接查询,并且该子查询是**`相关子查询`**,那么该子查询的第一个 SELECT 关键字对应的查询就是**` DEPENDENT SUBQUERY`

<mark>需要注意的是: DEPENDENT SUBQUERY的子查询可能会被执行多次!</mark>

![image-20220731230707414](./image/性能分析工具/image-20220731230707414.png)



##### DEPENDENT UNION

**如果子查询中包含** `UNION、UNION ALL`**的小查询,且该子查询是**`相关子查询`**,那么该子查询的第一个SELECT 关键字对应的是**`DEPENDENT SUBQUERY`**,其他的则都是**`DEPENDENT UNION`

![image-20220801090619430](./image/性能分析工具/image-20220801090619430.png)



##### DERIVED

对于包含`派生表`的查询,该派生表对应的子查询的 query_type 就是`DERIVED`

![image-20220801091628209](./image/性能分析工具/image-20220801091628209.png)



##### MATERIALIZED

当查询优化器在执行包含子查询的语句时,选择将子查询转为物化表之后与外层查询进行连接查询,那么该子查询的 query_type 就是`MATERIALIZED`

![image-20220801092435945](./image/性能分析工具/image-20220801092435945.png)



#### partitions

- **表示分区表中的命中情况,如果是非分区表,这个值为 `NULL`**,一般来说我们执行计划的 partitions 的值都是 null
- [官方文档](https://dev.mysql.com/doc/refman/5.7/en/partitioning-info.html)

:::info 测试分区

**1.创建分区表**

```sql
-- 创建分区表，按照id分区，id<100 p0分区，其他p1分区
CREATE TABLE user_partitions (
  	id INT PRIMARY KEY auto_increment,
		NAME VARCHAR(12)
)
  PARTITION BY RANGE(id)(
				PARTITION p0 VALUES less than(100),
        PARTITION p1 VALUES less than MAXVALUE
);
```



**2.测试分区信息**

![image-20220801093428783](./image/性能分析工具/image-20220801093428783.png)

:::

#### type🚧

执行计划的一条记录就代表着`MySQL 对某个表执行查询时的访问方法`,也叫做**访问类型**。其中的 `type` 列就表名了这个访问方法是啥,是一个重要的指标。

完整的访问方法如下所示:

1. `system`
2. `const`
3. `eq_ref`
4. `ref`
5. `fulltext`
6. `ref_or_null`
7. `index_merge`
8. `unique_subquery`
9. `index_subquery`
10. `range`
11. `index`
12. `all`

##### system

- 当表中`只有一条记录`,并且该表使用的存储引擎的统计数据是精确的,比如 MyISAM、Memory,那么对该表的访问是 `system`
- <mark>是一种特殊的 const</mark> 

![image-20220801094910549](./image/性能分析工具/image-20220801094910549.png)



##### const

- 概述

  - **如果某个表通过**`主键或唯一索引与常数进行等值匹配`**的时候,对该表的访问方法就是**`const`
    - <mark>常数值如果不在表中,那么 type 就是 null</mark>
    - <mark>不止适用于单表查询,也适用于 join 连接查询</mark>

- 基本格式

  ```sql
  -- 单一查询条件
  SELECT * FROM tbl_name 
  WHERE primary_key=constValue;
  
  -- 多个查询条件
  SELECT * FROM tbl_name 
  WHERE primary_key_part1=constValue AND primary_key_part2=constValue2;
  ```

![image-20220801100338422](./image/性能分析工具/image-20220801100338422.png)



##### eq_ref

- 概述

  - 在连接查询时,如果`被驱动表`是通过`主键或者唯一索引列与驱动表进行等值匹配`的方式进行访问的,则对该被驱动表的访问方法是`eq_ref`
  - <mark>如果主键或者唯一索引列是联合索引的话,所有的索引列都必须进行等值比较,最多只会返回一条符合条件的记录</mark>

- 基本格式

  ```sql
  /*
  	key_column:主键、唯一索引
  */
  -- 连接查询, 主键或唯一索引与驱动表进行等值匹配
  SELECT *  FROM ref_table,other_table
  WHERE ref_table.key_column=other_table.column;
  
  
  SELECT * FROM ref_table,other_table
  WHERE ref_table.key_column_part1=other_table.column
  AND ref_table.key_column_part2=constValue;
  ```

  

:::info 示例

可以看到 s2 作为被驱动表,通过主键与 s1 等值匹配,所以对s2 的方法方法是eq_ref

![image-20220801102444370](./image/性能分析工具/image-20220801102444370.png)

:::

##### ref

- 概述

  - 当`普通的二级索引与常量进行等值匹配`时来查询某个表,那么这个表的访问方法就是`ref`
  - 在连接查询时,如果`被驱动表`是通过`普通的二级索引与驱动表进行等值匹配`的方式进行访问的,则对该被驱动表的访问方法是`ref`
  - <mark>可能会返回多个符合条件的行</mark>

- **基本格式**

  ```sql
  /*
  	key_column:普通二级索引
  */
  -- 单表查询,普通二级索引与常量等值匹配
  SELECT * FROM ref_table WHERE key_column=constValue;
  
  -- 连接查询,普通二级索引与驱动表进行等值匹配
  SELECT * FROM ref_table,other_table
  WHERE ref_table.key_column=other_table.column;
  ```

  

![image-20220801102020671](./image/性能分析工具/image-20220801102020671.png)



##### ref_or_null

- **概述**

  - 当对`普通二级索引进行等值匹配查询时`,且该普通二级索引列的值也可以为`NULL`时,那么对该表的方法方法是`ref_or_null`

- **基本格式**

  ```sql
  /*
  	key_column:普通二级索引
  */
  -- 单表或者连接查询中,普通二级索引进行等值匹配查询,或者普通二级索引可以为 NULL
  SELECT * FROM ref_table
  WHERE key_column=expr OR key_column IS NULL;
  ```

  

![image-20220801104330922](./image/性能分析工具/image-20220801104330922.png)



##### index_merge

- **概述**

  - 合并索引
  - 一般情况下对于某个表的查询只能使用到一个索引，但在某些场景下可以使用多种索引合并的方式来执行查询

- **基本格式**

  ```sql
  -- 格式 1
  SELECT * FROM tbl_name 
  WHERE key1 = const_key1_val OR key2 = const_key2_val;
  
  -- 格式 2
  SELECT * FROM tbl_name
  WHERE (
    			key1 = const_key1_val OR key2 = const_key2_val
  			) 
  			AND non_key = non_key_value;
  
  -- 格式 3
  SELECT * FROM t1, t2
  WHERE (
    			t1.key1 IN (const_key1_val1,const_key1_val2) 
    			OR t1.key2 LIKE 'const_key2_val%'
        )
  AND t2.key1 = t1.some_col;
  
  -- 格式 4
  SELECT * FROM t1, t2
  WHERE t1.key1 = const_key1_val
  AND (t2.key1 = t1.some_col OR t2.key2 = t1.some_col2);
  ```

- 合并的等价

  ```sql
  -- 等价 1
  (x AND y) OR z => (x OR z) AND (y OR z)
  
  -- 等价 2
  (x OR y) AND z => (x AND z) OR (y AND z)
  ```

  

![image-20220801104820012](./image/性能分析工具/image-20220801104820012.png)



##### unique_subquery

- **概述**

  - 针对一些在`IN 子查询`的查询语句中,如果优化器将 IN 子查询转为`Exists 子查询`,而且子查询可以`使用到主键进行等值匹配`的话,那么这个子查询的 type 就是`unique_query`

- **基本语法**

  ```sql
  value IN (SELECT primary_key FROM single_table WHERE some_expr) some_expr
  ```

![image-20220801125626158](./image/性能分析工具/image-20220801125626158.png)



##### index_subquery

- **概述**

  - 针对一些在`IN 子查询`的查询语句中,如果优化器将 IN 子查询转为`Exists 子查询`,而且子查询可以`使用到唯一索引进行等值匹配`的话,那么这个子查询的 type 就是`index_query`

- **基本格式**

  ```sql
  value IN (SELECT key_column FROM single_table WHERE some_expr) some_expr
  ```

![image-20220801144418918](./image/性能分析工具/image-20220801144418918.png)

##### range

- **概述**

  - 如果使用索引获取某些`范围区间`的记录,那么就会使用`range`访问方法
  - 范围扫描通常出现在 `in 、between 、> 、< 、 >= 、 <=`等操作中

- **基本格式**

  ```sql
  SELECT * FROM tbl_name
  WHERE key_column BETWEEN constValue1 and constValue2;
  
  SELECT * FROM tbl_name
  WHERE key_column IN (constValue1,constValue2,constValue3);
  
  SELECT * FROM tbl_name
  WHERE key_part1 = constValue1 
  AND key_part2 IN (constValue2,constValue3,constValue4);
  
  -- ...
  ```

  ![image-20220801142530312](./image/性能分析工具/image-20220801142530312.png)



##### index

- 当我们可以使用**索引覆盖**,但是需要**扫描全部的索引记录时**,那么就会使用`index`访问方法
  - 虽然 where 条件无法使用户索引,但是查询条件中用到了索引,于是扫描全表索引
- 索引覆盖: 简单的说就是不用回表,就可以查询到需要的字段

![image-20220801142903772](./image/性能分析工具/image-20220801142903772.png)



##### all

就是全表扫描,性能最差

:::tip 说明

1. 一般来说,上面的访问方法除了`ALL`之外,都用到了索引,除了`index_merge`都只用了1 个索引
2. 性能从高到低依次为: `system、const、eq_ref、ref、fulltext、ref_or_null、index_merge、unique_subquery、index_subquery、range、index、all`
3. 性能优化目标:至少达到 range 级别,要求是 ref 级别,最好是 consts 级别

:::

#### possible_key 和 key

- `possible_keys`
  - 查询中可能的索引
- `key`
  - 查询优化器计算完不同索引的成本后,最后决定的实际使用的索引
  - 如果为 NULL,则说明没有使用索引

![image-20220801152046842](./image/性能分析工具/image-20220801152046842.png)



#### key_len 🚧

- **说明**
  - 实际使用到的**索引长度(字节数)**
  - 主要针对`联合索引`,可以帮助我们检查**是否充分的利用上了索引**, `值越大越好`

- **不同编码的字符长度**
  - `utf8` : 3字节
  - `gbk`  : 2字节
  - `latin1` : 1字节

- **如何计算?**
  - <mark>varchar</mark>

    - **varchar(10) 允许为 NULL** : 10*(编码的字符长度) + 1(Null) + 2(变长字段)
    - **varchar(10) 不允许为 NULL** : 10*(编码的字符长度) + 2(变长字段)
  - <mark>char</mark>

    - **char(10) 允许为 NULL**: 10*(编码的字符长度) + 1(Null)
    - **char(10) 不允许为 NULL** : 10*(编码的字符长度)
  - <mark>int: 4字节</mark>
  - <mark>tinyint：1字节</mark>
  - <mark>bigint：8字节</mark>
  - <mark>date：3字节</mark>
  - <mark>timestamp：4字节</mark>
  - <mark>datetime：8字节</mark>

![image-20220801160101558](./image/性能分析工具/image-20220801160101558.png)



#### ref

**当使用索引列等值查询时,与索引列进行等值查询匹配的对象信息**。比如`一个常数、某个列`

![image-20220801161541815](./image/性能分析工具/image-20220801161541815.png)



#### rows🚧

- **预估需要读取并判断的记录条数**,`值越小越好`
  - <mark>注意:这里的 rows 不是返回结果集的记录数</mark>
- 如果查询优化器决定使用**全表扫描**的方式对某个表执行查询时，执行计划的rows列就代表预计需要扫描的行数
- 如果**使用索引**来执行查询时，执行计划的rows列就代表预计扫描的**索引记录行数** 

![image-20220801162101355](./image/性能分析工具/image-20220801162101355.png)



#### filtered

- **某个表进过搜索条件过滤后剩余记录条数的百分比**,`值越大越好`
  - 如果使用的是索引且进行单表扫描,那么计算时需要估计出满足除使用索引外,其他搜索条件的记录数
- 对于单表查询来说,这个filter 没有什么意义,我们`更加关注连接查询中驱动表对应的执行计划的 filtered 的值`,它决定了`被驱动表要执行的次数: rows * filtered`

:::info

**1. 连接查询驱动表的 rows + filtered**

可以看到,s1是驱动表,s2 是被驱动表。s2的执行次数: 9895*10% ≈990 次

![image-20220801163315592](./image/性能分析工具/image-20220801163315592.png)

:::

#### Extra🚧

-  **用于说明一些额外信息的,包含不适合在其他列中显示,但是很重要的额外信息**,我们可以通过这些额外信息来`更准确的理解 MySQL 将如何执行给定的查询语句`

- **常见的信息**

  - `No tables used` 

    - 当查询语句中没有 FROM 子句

  - `Impossible WHERE`

    - 查询语句 where 子句永远是 false

  - `Using where`

    - 使用全表扫描来执行对某个表的查询,并且该语句的`WHERE`子句中有针对该表的检索条件时

    - 使用索引来对某个表进行查询,并且`WHERE`子句中除了该索引,还有其他搜索条件时

  - `No matching min/max row`

    - 当查询列表中有`MIN、MAX`聚合函数,但是没有符合`WHERE`子句中的搜索条件的记录时

  - `Using index`

    - 查询列表以及搜索条件中只包含索引列
    - 可以使用覆盖索引,不需要进行回表

  - `Using index condition`

    - 有些搜索条件虽然出现了索引列,但是却没有能使用索引

  - `Using join buffer (Block Nested Loop)`

    - 在连接查询的时候,当被驱动表不能有效的利用索引时,MySQL 一般会为其分配一块名为`join buffer` 的内存块来加快查询速度,即`基于块的嵌套循环算法`

  - `Not exists`

    - 当使用左连接时,如果`where`子句中包含要求被驱动表的某个列等于`NULL`值的搜索条件,但那个列时不允许为 NULL 的

  - `Zero limit`

    - 当 LIMIT 子句的参数为`0`时,即不打算从表中读取任何记录

  - `Using filesort`

    - 很多情况下,排序操作无法使用到索引,只能在内存中(记录较少是时)或者磁盘中(记录较多时)进行排序,这种需要再内存或磁盘上进行排序的就是文件排序

  - `Using temporary`

    - 在很多查询的执行过程中,MySQL 需要借助临时表完成一些功能,比如去重、排序等
    - **执行计划中出现了使用临时表不是很好的体现,会有一个较高的成本**

### 小结

- **EXPLAIN不考虑各种Cache**
- **EXPLAIN不能显示MySQL在执行查询时所作的优化工作**
- **EXPLAIN不会告诉你关于触发器、存储过程的信息或用户自定义函数对查询的影响情况**
- **部分统计信息是估算的，并非精确值**



## Explain 拓展

#### 其他输出方式

> Explain 提供了多种的输出格式,主要有以下的3种:
>
> 1. **传统格式**
>    - 这种方式就是上面使用的
> 2. **JSON 格式**
>    - `EXPLAIN FORMAT=JSON SQL语句`
> 3. **Tree 格式**
>    - `EXPLAIN FORMAT=tree SQL语句`

#### JSON 格式

- 传统的Explain输出中缺少了了一个衡量执行计划好坏的重要属性:`成本`,而 JSON 格式是四种输出格式里面`信息最详细的格式`,其中就包含了`执行成本信息`
- **返回 JSON 部分属性说明**
  - **cost_info#query_cost**: 查询成本
  - **nested_loop#table#cost_info** :花费成本(最外层节点)
    - **read_cost**
      - 由下面两部分组成
        - IO 成本
        - 检测 `rows × (1 - filter)` 条记录的 `CPU` 成本
    - **eval_cost**
      - 检测 `rows × filter` 条记录的成本。
    - **prefix_cost**
      - `read_cost + eval_cost`
    - **data_read_per_join**
      - 在此次查询中需要读取的数据量

**Explain 传统输出列 与 JSON格式属性的对应关系**

|   传统输出列    | 对应 JSON 属性  |
| :-------------: | :-------------: |
|      `id`       |   `select_id`   |
|  `select_type`  |        ❌        |
|     `table`     |  `table_name`   |
|  `partitions`   |  `partitions`   |
|     `type`      |  `access_type`  |
| `possible_keys` | `possible_keys` |
|      `key`      |      `key`      |
|    `key_len`    |  `key_length`   |
|      `ref`      |      `ref`      |
|     `rows`      |     `rows`      |
|   `filtered`    |   `filtered`    |
|     `Extra`     |        ❌        |



:::info 示例

**1.explain分析查询语句**

```sql
Explain format=JSON 
select * from s1 inner join s2 on s1.key1=s2.key2 where s1.common_field='a'\G;
```

**2.返回的 JSON 数据**

```json
 {
  "query_block": {
    "select_id": 1,
    "cost_info": {
      "query_cost": "1360.07"
    },
    "nested_loop": [
      {
        "table": {
          "table_name": "s1",
          "access_type": "ALL",
          "possible_keys": ["idx_key1"],
          "rows_examined_per_scan": 9895,
          "rows_produced_per_join": 989,
          "filtered": "10.00",
          "cost_info": {
            "read_cost": "914.80",
            "eval_cost": "98.95",
            "prefix_cost": "1013.75",
            "data_read_per_join": "1M"
          },
          "used_columns": [...],
          "attached_condition": "((`atguigu1`.`s1`.`common_field` = 'a') and (`atguigu1`.`s1`.`key1` is not null))"
        }
      },
      {
        "table": {
          "table_name": "s2",
          "access_type": "eq_ref",
          "possible_keys": ["idx_key2"],
          "key": "idx_key2",
          "used_key_parts": [ "key2"],
          "key_length": "5",
          "ref": ["atguigu1.s1.key1"],
          "rows_examined_per_scan": 1,
          "rows_produced_per_join": 989,
          "filtered": "100.00",
          "index_condition": "(cast(`atguigu1`.`s1`.`key1` as double) = cast(`atguigu1`.`s2`.`key2` as double))",
          "cost_info": {
            "read_cost": "247.38",
            "eval_cost": "98.95",
            "prefix_cost": "1360.08",
            "data_read_per_join": "1M"
          },
          "used_columns": [...],
        }
      }
    ]
  }
}
```

:::



#### TREE 格式

TREE格式是**8.0.16**版本之后引入的新格式，主要根据查询的 `各个部分之间的关系` 和 `各部分的执行顺序` 来描述如何查询

![image-20220801233243927](./image/性能分析工具/image-20220801233243927.png)

### SHOW WARNINGS

在我们使用 explain 查看某个查询的执行计划后,可以紧接着使用`SHOW WARNINGS`查看和这个执行计划有关的拓展信息

:::info

有两个警告信息:

1. 无法使用表s1 的索引 key1
2. 原本的子查询变成了 join 连接查询,并且由于 key1 与 id 的类型不匹配,发生了隐式转换

![image-20220801234542111](./image/性能分析工具/image-20220801234542111.png)

:::

## 分析优化器执行计划-Trace

`OPTIMIZER_TRACE` 是 MySQL5.6 引入的一项跟踪功能,**可以跟踪优化器做出的各种决策(比如访问表的方法、各种开销计算、各种转换等)**,并且将跟踪结果记录到`information_schema.OPTIMIZER_TRACE`

### 开启 trace

这个功能默认是`关闭`的,可以通过以下的方式开启:

```sql
-- 开启 trace,设置格式为 JSON
set optimizer_trace="enabled=ON",end_markers_in_json=on;

-- 设置 trace能使用的最大内存大小
set optimizer_trace_max_mem_size=1000000;
```

在开启 trace 之后,可以分析以下的语句:

1. `SELECT`
2. `INSERT`
3. `REPLACE`
4. `UPDATE`
5. `DELETE`
6. `EXPLAIN`
7. `SET` 
8. `DECLARE`
9. `CASE`
10. `IF` 
11. `RETURN` 
12. `CALL` 

## 监控分析视图-sys_schema

> 关于 MySQL 的性能监控和问题诊断,我们一般都从 performance_schema 中获取想要的数据,在 MySQL5.7.7 版本以后新家了 sys_schema,它将 performance_schema 和 information_schema 的数据以更容易理解的方式归纳为视图,用于`降低查询 performance_schema 的复杂度`,可以快速的定位问题

### Sys_schem 视图摘要

1. **主机相关:**
   - 以host_summary开头，主要汇总了IO延迟的信息
2. **Innodb相关:**
   - 以innodb开头，汇总了innodb buffer信息和事务等待innodb锁的信息
3. I/o**相关:**
   - 以io开头，汇总了等待I/O、I/O使用量情况
4. **内存使用情况:**
   - 以memory开头，从主机、线程、事件等角度展示内存的使用情况
5. **连接与会话信息:**
   - processlist和session相关视图，总结了会话相关信息
6. **表相关:**
   - 以schema_table开头的视图，展示了表的统计信息
7. **索引信息:**
   - 统计了索引的使用情况，包含冗余索引和未使用的索引情况
8. **语句相关:**
   - 以statement开头，包含执行全表扫描、使用临时表、排序等的语句信息
9. **用户相关:**
   - 以user开头的视图，统计了用户使用的文件I/O、执行语句统计信息
10. **等待事件相关信息:**
    - 以wait开头，展示等待事件的延迟情况

### Sys_schema 视图使用场景

#### 索引情况

```sql
#1. 查询冗余索引
select * from sys.schema_redundant_indexes;

#2. 查询未使用过的索引
select * from sys.schema_unused_indexes;

#3. 查询索引的使用情况
select index_name,rows_selected,rows_inserted,rows_updated,rows_deleted 
from sys.schema_index_statistics
where table_schema='dbname' ;
```

#### 表相关

```sql
# 1. 查询表的访问量
select table_schema,table_name,sum(io_read_requests+io_write_requests) as io 
from sys.schema_table_statistics 
group by table_schema,table_name 
order by io desc;

# 2. 查询占用bufferpool较多的表
select object_schema,object_name,allocated,data
from sys.innodb_buffer_stats_by_table 
order by allocated limit 10;

# 3. 查看表的全表扫描情况
select * from sys.statements_with_full_table_scans where db='dbname';
```

#### 语句相关

```sql
#1. 监控SQL执行的频率
select db,exec_count,query 
from sys.statement_analysis order by exec_count desc;

#2. 监控使用了排序的SQL
select db,exec_count,first_seen,last_seen,query 
from sys.statements_with_sorting limit 1;

#3. 监控使用了临时表或者磁盘临时表的SQL
select db,exec_count,tmp_tables,tmp_disk_tables,query
from sys.statement_analysis 
where tmp_tables>0 or tmp_disk_tables >0 
order by (tmp_tables+tmp_disk_tables) desc;
```

#### IO相关

```sql
#1. 查看消耗磁盘IO的文件
select file,avg_read,avg_write,avg_read+avg_write as avg_io
from sys.io_global_by_file_by_bytes order by avg_read limit 10;
```

#### Innodb 相关

```sql
#1. 行锁阻塞情况
select * from sys.innodb_lock_waits;
```

